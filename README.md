# thefcraft-ai-nn
This is a basic example of how to make neural networks from scratch (you can replace numpy with c++ and cuda)
- in this code i use autograd/micrograd like implementation to track the gradients.

## DEMO
results.txt
```
EPOCH: 0 | LOSS: 0.1732
EPOCH: 100 | LOSS: 0.1672
EPOCH: 200 | LOSS: 0.1614
EPOCH: 300 | LOSS: 0.1561
EPOCH: 400 | LOSS: 0.1510
EPOCH: 500 | LOSS: 0.1463
EPOCH: 600 | LOSS: 0.1418
EPOCH: 700 | LOSS: 0.1376
EPOCH: 800 | LOSS: 0.1336
EPOCH: 900 | LOSS: 0.1299
EPOCH: 1000 | LOSS: 0.1263
EPOCH: 1100 | LOSS: 0.1229
EPOCH: 1200 | LOSS: 0.1197
EPOCH: 1300 | LOSS: 0.1167
EPOCH: 1400 | LOSS: 0.1138
EPOCH: 1500 | LOSS: 0.1111
EPOCH: 1600 | LOSS: 0.1085
EPOCH: 1700 | LOSS: 0.1060
EPOCH: 1800 | LOSS: 0.1037
EPOCH: 1900 | LOSS: 0.1014
EPOCH: 2000 | LOSS: 0.0993
EPOCH: 2100 | LOSS: 0.0972
EPOCH: 2200 | LOSS: 0.0952
EPOCH: 2300 | LOSS: 0.0933
EPOCH: 2400 | LOSS: 0.0915
EPOCH: 2500 | LOSS: 0.0898
EPOCH: 2600 | LOSS: 0.0881
EPOCH: 2700 | LOSS: 0.0865
EPOCH: 2800 | LOSS: 0.0849
EPOCH: 2900 | LOSS: 0.0834
EPOCH: 3000 | LOSS: 0.0820
EPOCH: 3100 | LOSS: 0.0806
EPOCH: 3200 | LOSS: 0.0792
EPOCH: 3300 | LOSS: 0.0779
EPOCH: 3400 | LOSS: 0.0767
EPOCH: 3500 | LOSS: 0.0755
EPOCH: 3600 | LOSS: 0.0743
EPOCH: 3700 | LOSS: 0.0732
EPOCH: 3800 | LOSS: 0.0721
EPOCH: 3900 | LOSS: 0.0710
EPOCH: 4000 | LOSS: 0.0699
EPOCH: 4100 | LOSS: 0.0689
EPOCH: 4200 | LOSS: 0.0680
EPOCH: 4300 | LOSS: 0.0670
EPOCH: 4400 | LOSS: 0.0661
EPOCH: 4500 | LOSS: 0.0652
EPOCH: 4600 | LOSS: 0.0643
EPOCH: 4700 | LOSS: 0.0635
EPOCH: 4800 | LOSS: 0.0626
EPOCH: 4900 | LOSS: 0.0618
Accuracy on test data: 0.9474
```
